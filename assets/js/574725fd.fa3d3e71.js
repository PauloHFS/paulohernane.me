"use strict";(self.webpackChunkpaulohernane_me=self.webpackChunkpaulohernane_me||[]).push([[5963],{3905:(e,t,n)=>{n.d(t,{Zo:()=>c,kt:()=>m});var r=n(7294);function a(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function s(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){a(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,r,a=function(e,t){if(null==e)return{};var n,r,a={},o=Object.keys(e);for(r=0;r<o.length;r++)n=o[r],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(r=0;r<o.length;r++)n=o[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var i=r.createContext({}),u=function(e){var t=r.useContext(i),n=t;return e&&(n="function"==typeof e?e(t):s(s({},t),e)),n},c=function(e){var t=u(e.components);return r.createElement(i.Provider,{value:t},e.children)},p="mdxType",d={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},h=r.forwardRef((function(e,t){var n=e.components,a=e.mdxType,o=e.originalType,i=e.parentName,c=l(e,["components","mdxType","originalType","parentName"]),p=u(n),h=a,m=p["".concat(i,".").concat(h)]||p[h]||d[h]||o;return n?r.createElement(m,s(s({ref:t},c),{},{components:n})):r.createElement(m,s({ref:t},c))}));function m(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var o=n.length,s=new Array(o);s[0]=h;var l={};for(var i in t)hasOwnProperty.call(t,i)&&(l[i]=t[i]);l.originalType=e,l[p]="string"==typeof e?e:a,s[1]=l;for(var u=2;u<o;u++)s[u]=n[u];return r.createElement.apply(null,s)}return r.createElement.apply(null,n)}h.displayName="MDXCreateElement"},1524:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>i,contentTitle:()=>s,default:()=>d,frontMatter:()=>o,metadata:()=>l,toc:()=>u});var r=n(7462),a=(n(7294),n(3905));const o={id:"threads-and-process-in-python",title:"Threads and Process in Python",tags:["Concurrent Programming"]},s=void 0,l={unversionedId:"concurrent-programming/threads-and-process-in-python",id:"concurrent-programming/threads-and-process-in-python",title:"Threads and Process in Python",description:"Introduction",source:"@site/my-brain/concurrent-programming/threads-and-process-in-python.md",sourceDirName:"concurrent-programming",slug:"/concurrent-programming/threads-and-process-in-python",permalink:"/my-brain/concurrent-programming/threads-and-process-in-python",draft:!1,tags:[{label:"Concurrent Programming",permalink:"/my-brain/tags/concurrent-programming"}],version:"current",frontMatter:{id:"threads-and-process-in-python",title:"Threads and Process in Python",tags:["Concurrent Programming"]},sidebar:"myBrainSidebar",previous:{title:"Mutual Exclusion Algorithms",permalink:"/my-brain/concurrent-programming/some-algorithms"},next:{title:"Data Science",permalink:"/my-brain/data-science/"}},i={},u=[{value:"Introduction",id:"introduction",level:2},{value:"Threads",id:"threads",level:2},{value:"Keep in mind",id:"keep-in-mind",level:3},{value:"ThreadPool",id:"threadpool",level:2},{value:"Keep in mind",id:"keep-in-mind-1",level:3},{value:"ThreadPoolExecutor",id:"threadpoolexecutor",level:2},{value:"Keep in mind",id:"keep-in-mind-2",level:3},{value:"Processes",id:"processes",level:2},{value:"Keep in mind",id:"keep-in-mind-3",level:3},{value:"Pool",id:"pool",level:2},{value:"Keep in mind",id:"keep-in-mind-4",level:3},{value:"ProcessPoolExecutor",id:"processpoolexecutor",level:3},{value:"Keep in mind",id:"keep-in-mind-5",level:3},{value:"What to use?",id:"what-to-use",level:2},{value:"References",id:"references",level:2}],c={toc:u},p="wrapper";function d(e){let{components:t,...n}=e;return(0,a.kt)(p,(0,r.Z)({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("h2",{id:"introduction"},"Introduction"),(0,a.kt)("p",null,"To apply concurrency in python we can use threads or processes. To exemplify I will use parallel loops to demonstrate the technics."),(0,a.kt)("h2",{id:"threads"},"Threads"),(0,a.kt)("p",null,"We can create a new thread for each iteration of a loop."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-py"},"# SuperFastPython.com\n# example of a parallel for loop with the Thread class\nfrom threading import Thread\n\n# execute a task\ndef task(value):\n    # add your work here...\n    # ...\n    # all done\n    print(f'.done {value}')\n\n# protect the entry point\nif __name__ == '__main__':\n    # create all tasks\n    threads = [Thread(target=task, args=(i,)) for i in range(20)]\n    # start all threads\n    for thread in threads:\n        thread.start()\n    # wait for all threads to complete\n    for thread in threads:\n        thread.join()\n    # report that all tasks are completed\n    print('Done')\n")),(0,a.kt)("h3",{id:"keep-in-mind"},"Keep in mind"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"This is good to small number of tasks."),(0,a.kt)("li",{parentName:"ul"},"Don't scale well, if you have a lot of tasks it will slow down cause they will compete for the CPU."),(0,a.kt)("li",{parentName:"ul"},"The results from tasks can't be returned easily.")),(0,a.kt)("h2",{id:"threadpool"},"ThreadPool"),(0,a.kt)("p",null,"We can use a thread pool to reuse threads. This is programming pattern that handles the creation and management of threads for us."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-py"},"# SuperFastPython.com\n# example of a parallel for loop with the ThreadPool class\nfrom multiprocessing.pool import ThreadPool\n\n# execute a task\ndef task(value):\n    # add your work here...\n    # ...\n    # return a result, if needed\n    return value\n\n# protect the entry point\nif __name__ == '__main__':\n    # create the pool with the default number of workers\n    with ThreadPool() as pool:\n        # issue one task for each call to the function\n        for result in pool.map(task, range(100)):\n            # handle the result\n            print(f'>got {result}')\n    # report that all tasks are completed\n    print('Done')\n\n")),(0,a.kt)("h3",{id:"keep-in-mind-1"},"Keep in mind"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"This is good to runs tasks that involve calling the same function many times with different arguments."),(0,a.kt)("li",{parentName:"ul"},"You can use functions instead of ",(0,a.kt)("inlineCode",{parentName:"li"},"map")," to run different functions in parallel, using lazy, multiples args, async, etc.")),(0,a.kt)("h2",{id:"threadpoolexecutor"},"ThreadPoolExecutor"),(0,a.kt)("p",null,"We can create a pool of worker threads using the ThreadPoolExecutor class with a modern executor interface."),(0,a.kt)("p",null,"This allows tasks to be issued as one-off tasks via the submit() method, returning Future object that provides a handle on the task. It also allows the same function to be called many times with different arguments via the map() method."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-py"},"# SuperFastPython.com\n# example of a parallel for loop with the ThreadPoolExecutor class\nimport concurrent.futures\n\n# execute a task\ndef task(value):\n    # add your work here...\n    # return a result, if needed\n    return value\n\n# protect the entry point\nif __name__ == '__main__':\n    # create the pool with the default number of workers\n    with concurrent.futures.ThreadPoolExecutor() as exe:\n        # issue some tasks and collect futures\n        futures = [exe.submit(task, i) for i in range(50)]\n        # handle results as tasks are completed\n        for future in concurrent.futures.as_completed(futures):\n            print(f'>got {future.result}')\n        # issue one task for each call to the function\n        for result in exe.map(task, range(50)):\n            print(f'>got {result}')\n    # report that all tasks are completed\n    print('Done')\n")),(0,a.kt)("h3",{id:"keep-in-mind-2"},"Keep in mind"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"This is the preferred approach to run parallel for-loops."),(0,a.kt)("li",{parentName:"ul"},"This is good to run one-off tasks as well as many calls to the same function with different arguments.")),(0,a.kt)("h2",{id:"processes"},"Processes"),(0,a.kt)("p",null,"We can create a new child process for each iteration of the loop."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-py"},"# SuperFastPython.com\n# example of a parallel for loop with the Process class\nfrom multiprocessing import Process\n\n# execute a task\ndef task(value):\n    # add your work here...\n    # ...\n    # all done\n    print(f'.done {value}', flush=True)\n\n# protect the entry point\nif __name__ == '__main__':\n    # create all tasks\n    processes = [Process(target=task, args=(i,)) for i in range(20)]\n    # start all processes\n    for process in processes:\n        process.start()\n    # wait for all processes to complete\n    for process in processes:\n        process.join()\n    # report that all tasks are completed\n    print('Done')\n")),(0,a.kt)("h3",{id:"keep-in-mind-3"},"Keep in mind"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"This is good to small number of tasks."),(0,a.kt)("li",{parentName:"ul"},"Don't scale well, if you have more tasks that CPU cores it will slow down cause they will compete for the CPU."),(0,a.kt)("li",{parentName:"ul"},"The results from tasks can't be returned easily.")),(0,a.kt)("h2",{id:"pool"},"Pool"),(0,a.kt)("p",null,"We can create a pool of worker processes that can be reused for many tasks."),(0,a.kt)("p",null,"This can be achieved using the Pool class that will create one worker for each logical CPU core in the system."),(0,a.kt)("p",null,"The Pool class can be created using the context manager interface, which ensures that it is closed and all workers are released once we are finished with it."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-py"},"# SuperFastPython.com\n# example of a parallel for loop with the Pool class\nfrom multiprocessing import Pool\n\n# execute a task\ndef task(value):\n    # add your work here...\n    # ...\n    # return a result, if needed\n    return value\n\n# protect the entry point\nif __name__ == '__main__':\n    # create the pool with the default number of workers\n    with Pool() as pool:\n        # issue one task for each call to the function\n        for result in pool.map(task, range(100)):\n            # handle the result\n            print(f'>got {result}')\n    # report that all tasks are completed\n    print('Done')\n")),(0,a.kt)("h3",{id:"keep-in-mind-4"},"Keep in mind"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"This is good to runs tasks that involve calling the same function many times with different arguments."),(0,a.kt)("li",{parentName:"ul"},"You can use functions instead of ",(0,a.kt)("inlineCode",{parentName:"li"},"map")," to run different functions in parallel, using lazy, multiples args, async, etc.")),(0,a.kt)("h3",{id:"processpoolexecutor"},"ProcessPoolExecutor"),(0,a.kt)("p",null,"we can create a pool of worker processes using the ProcessPoolExecutor class with a modern executor interface."),(0,a.kt)("p",null,"This allows tasks to be issued as one-off tasks via the ",(0,a.kt)("inlineCode",{parentName:"p"},"submit()")," method, returning Future object that provides a handle on the task. It also allows the same function to be called many times with different arguments via the ",(0,a.kt)("inlineCode",{parentName:"p"},"map()")," method."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-py"},"# SuperFastPython.com\n# example of a parallel for loop with the ProcessPoolExecutor class\nimport concurrent.futures\n\n# execute a task\ndef task(value):\n    # add your work here...\n    # return a result, if needed\n    return value\n\n# protect the entry point\nif __name__ == '__main__':\n    # create the pool with the default number of workers\n    with concurrent.futures.ProcessPoolExecutor() as exe:\n        # issue some tasks and collect futures\n        futures = [exe.submit(task, i) for i in range(50)]\n        # process results as tasks are completed\n        for future in concurrent.futures.as_completed(futures):\n            print(f'>got {future.result}')\n        # issue one task for each call to the function\n        for result in exe.map(task, range(50)):\n            print(f'>got {result}')\n    # report that all tasks are completed\n    print('Done')\n")),(0,a.kt)("h3",{id:"keep-in-mind-5"},"Keep in mind"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"This is the preferred approach to run parallel for-loops."),(0,a.kt)("li",{parentName:"ul"},"This is good to run one-off tasks as well as many calls to the same function with different arguments.")),(0,a.kt)("h2",{id:"what-to-use"},"What to use?"),(0,a.kt)("p",null,"When you Threads or Processes depends of the problem you are trying to solve."),(0,a.kt)("p",null,(0,a.kt)("strong",{parentName:"p"},"Thread-based concurrency is good for I/O-bound tasks"),", such as reading and writing files, network communication, database access, interact with devices, etc. This is note good for CPU-bound tasks because the GIL will prevent the threads from running in parallel, so threads are better, cause when one is waiting for I/O the GIL is release and another thread can run."),(0,a.kt)("p",null,(0,a.kt)("strong",{parentName:"p"},"Process-based concurrency is good for CPU-bound tasks")," like calculating, parsing, encoding and modeling, such as image processing, video encoding, machine learning, etc. If you do this type of operations in threads, each task will be locked by GIL."),(0,a.kt)("p",null,"Prefer to use the ",(0,a.kt)("inlineCode",{parentName:"p"},"ThreadPoolExecutor")," or ",(0,a.kt)("inlineCode",{parentName:"p"},"ProcessPoolExecutor")," classes to run parallel for-loops."),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Better interface to run the tasks."),(0,a.kt)("li",{parentName:"ul"},"Better performance by run only the number of tasks that can be run in parallel."),(0,a.kt)("li",{parentName:"ul"},"Better performance by reusing threads or processes."),(0,a.kt)("li",{parentName:"ul"},"When submitting tasks, they are queued and run as soon as a worker is available.")),(0,a.kt)("h2",{id:"references"},"References"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("a",{parentName:"li",href:"https://superfastpython.com/threading-in-python/"},"Thread")),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("a",{parentName:"li",href:"https://superfastpython.com/threadpool-python/"},"ThreadPool")),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("a",{parentName:"li",href:"https://superfastpython.com/threadpoolexecutor-in-python/?ck_subscriber_id=2308580045&utm_source=convertkit&utm_medium=email&utm_campaign=Lesson+03%3A+Parallel+Loops+with+ThreadPoolExecutor%20-%205160219"},"ThreadPoolExecutor")),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("a",{parentName:"li",href:"https://click.convertkit-mail2.com/n4upknex0efquq2opna6h7mrlwgg/3ohphduq5g5w7nup/aHR0cHM6Ly9TdXBlckZhc3RQeXRob24uY29tL211bHRpcHJvY2Vzc2luZy1pbi1weXRob24v"},"Process")),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("a",{parentName:"li",href:"https://click.convertkit-mail2.com/r8u5ozvd0vb9udk5rwi2hxkp3n66/7qh7h2u027w3l7c9/aHR0cHM6Ly9TdXBlckZhc3RQeXRob24uY29tL211bHRpcHJvY2Vzc2luZy1wb29sLXB5dGhvbi8="},"Pool")),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("a",{parentName:"li",href:"https://superfastpython.com/processpoolexecutor-in-python/?ck_subscriber_id=2308580045&utm_source=convertkit&utm_medium=email&utm_campaign=Lesson+06%3A+Parallel+Loop+with+ProcessPoolExecutor%20-%205160227"},"ProcessPoolExecutor"))))}d.isMDXComponent=!0}}]);